akka {
  coordinated-shutdown.exit-jvm = on

  extensions = [
    akka.persistence.Persistence,
  ]

  actor {
    provider = cluster
  }

  remote.artery {
    transport = aeron-udp

    canonical {
      hostname = "127.0.0.1"
      hostname = ${?KUBERNETES_POD_IP}
      port = 25520
    }
    
    # See https://doc.akka.io/docs/akka/current/remoting-artery.html#remote-configuration-nat-artery
    # We are not really using this but will let it configured in case we need in the future. These are dummy values
    bind {
      hostname = "127.0.0.1"
      # IMPORTANT: This is the IP that will be used to bind the port. It should be the same as the one used in the canonical hostname
      # If not it breaks the TCP connection used when the Akka Cluster is forming in Kubernetes
      hostname = ${?KUBERNETES_POD_IP}
      port = 25520
    }
  }

  cluster {
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
    shutdown-after-unsuccessful-join-seed-nodes = 60s

    sharding {
      # See https://doc.akka.io/docs/akka/current/typed/cluster-sharding.html#shard-allocation
      number-of-shards = 100
      least-shard-allocation-strategy.rebalance-absolute-limit = 20
      buffer-size = 300000

      # See https://stackoverflow.com/questions/72506685/rebalance-akka-cluster-if-one-of-shard-is-not-resolving
      # Lower than 9 Cluster Nodes will required all nodes to acknowledge the rebalance
      # so we increase the timeout to decrease failures
      updating-state-timeout = 15 s
    }
  }

  persistence {
    state {
      plugin = "jdbc-durable-state-store"
    }
  }

  management {
    cluster.bootstrap {
      contact-point-discovery {
        discovery-method = kubernetes-api
      }
    }
  }

  # See https://github.com/lightbend/config/issues/356
  # Basically we can't use env variables inside child configs, so we need to use this workaround
  kafka-common-config {
    kafka-clients {
      bootstrap.servers = "localhost:9094"
      bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
      security.protocol = ${?KAFKA_SECURITY_PROTOCOL}
      sasl.mechanism = ${?KAFKA_SASL_MECHANISM}
      sasl.jaas.config = ${?KAFKA_SASL_JAAS_CONFIG}
    }
  }

  kafka-consumer: ${akka.kafka.consumer} ${akka.kafka-common-config} {}

  kafka-producer: ${akka.kafka.producer} ${akka.kafka-common-config} {}
}

jdbc-durable-state-store {
  slick = ${slick}
}

# Akka Persistence uses Slick's DatabaseConfig format instead of Database format
# See https://scala-slick.org/doc/stable/database.html#databaseconfig
slick {
  profile = "slick.jdbc.PostgresProfile$"
  db {
    host = "localhost:5432"
    host = ${?DB_HOST}
    database = akka
    database = ${?DB_DATABASE}
    url = "jdbc:postgresql://"${slick.db.host}"/"${slick.db.database}"?currentSchema=akka&reWriteBatchedInserts=true"
    user = "akka"
    user = ${?DB_USER}
    password = "akka"
    password = ${?DB_PASSWORD}
    connectionPool = "HikariCP"
    driver = "org.postgresql.Driver"
    numThreads = 2 # Default is 5, not using the default value because it must be equal or less than maxConnections
    maxConnections = 2 # Default is 5, not using the default value to avoid overloading the production database
    minConnections = 1
  }
}

# Game settings
game {
  kafka {
    topic = "game-zone"
    topic = ${?GAME_KAFKA_TOPIC}
    partitions = 4
    partitions = ${?GAME_KAFKA_PARTITIONS}
    consumer {
      group-prefix = "kafka-consumer"
      group-prefix = ${?GAME_KAFKA_CONSUMER_GROUP}
    }
  }

  player-acceptor {
    port = 2020
    port = ${?PLAYER_ACCEPTOR_PORT}
  }

  bots {
    perNode = 0
    perNode = ${?GAME_BOTS_PER_NODE}
    perCreationDelaySeconds = 20
    perCreationDelaySeconds = ${?GAME_BOTS_PER_CREATION_DELAY_SECONDS}
  }
}

cinnamon {
  akka {
    actors {
      "/user/*" {
        report-by = instance
      }

      "sharded-group" {
        report-by = instance
        includes = ["/system/sharding/*"]
        excludes = ["akka.cluster.sharding.Shard"]
      }
    }

    stream.partial = on

    # This config does not actually do anything because it only reports metrics based on
    # Event Sourcing based actors, which we don't have in this project (we are using Durable State Store ones)
    # Still, I leave it for reference / future use.
    persistence.entities {
      "sharded:?" {
        report-by = group
      }
    }

    cluster {
      domain-events = on
      member-events = on
      node-status = on
      singleton-events = on
      shard-region-info = on
      node-metrics = on
      split-brain-resolver-events = on
    }

    ask-pattern.actors {
      "akka.cluster.sharding.ShardRegion" {
        report-by = instance
      }
    }
  }

  prometheus {
    exporters += http-server
  }
}
